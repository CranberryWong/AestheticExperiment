## CHEC at CHI 2017


---
**Posted By: Kavous**

![Figure](https://farm1.staticflickr.com/917/41794635360_7469a7f152_c.jpg)

CHEC has 7 papers including 2 Full Papers, 2 Notes, 1 Workshop, 1 Late-Breaking Work and 1 Panel at CHI Conference on Human Factors in Computing Systems 2017. CHI is the most prestigious conference in the field of Human-Computer Interaction.  The papers cover different areas such as Mindfulness Interaction, Haptic Pen Interaction, Modeling for User Interaction, and Video Games for Cognitive Enhancement.

![Figure](https://farm5.staticflickr.com/4180/33992071754_680734a8e3_c.jpg)

**Human Computer Integration versus Powerful Tools**
*Farooq, U., Grudin, J., Shneiderman, B., Maes, P., Ren, X.*
Abstract: In 1960, JCR Licklider forecast three phases for how humans relate to machines: human-computer interaction, human-computer symbiosis, and ultra-intelligent machines. Have we moved from interaction to symbiosis or integration, should we focus on this or on other aspects of human augmentation via powerful tools, and how will such decisions affect us as designers, researchers, and members of society? This panel will raise uneasy and disruptive HCI notions. For example, we will debate whether integration is a necessary and desirable next phase, or whether it could undermine human self-efficacy and control and lessen the predictability of machine actions.
 
**Modelling Learning of New Keyboard Layouts**
*Jokinen, J., Sarcar, S., Oulasvirta, A., Silpasuwanchai, C., Wang, Z., Ren, X.*
Abstract: Predicting how users learn new or changed interfaces is a long-standing objective in HCI research. This paper contributes to understanding of visual search and learning in text entry. With a goal of explaining variance in novices’ typing performance that is attributable to visual search, a model was designed to predict how users learn to locate keys on a keyboard: initially relying on visual short-term memory but then transitioning to recall-based search. This allows predicting search times and visual search patterns for completely and partially new layouts. The model complements models of motor performance and learning in text entry by predicting change in visual search patterns over time. Practitioners can use it for estimating how long it takes to reach the desired level of performance with a given layout.
 
**Designing Mobile Interactions for the Ageing Populations**
*Sarcar, S.,Munteanu, C.,Jokinen, J.,Oulasvirta, A.,Silpasuwanchai, C.,Charness, N.,Dunlop, M.,Ren, X.*
Abstract: We are concurrently witnessing two significant shifts: mobiles are becoming the most used computing device; and older people are becoming the largest demographic group. However, despite the recent increase in related CHI publication, older adults continue to be underrepresented in HCI research as well as commercially, further widening the digital divide they face and hampering their social participation. This workshop aims to increase the momentum for such research within CHI and related fields such as gerontechnology. We plan to create a space for discussing and sharing principles and strategies to design and evaluate mobile user interfaces for the ageing population. We thus welcome contributions to empirical studies, theories, design and evaluation of mobile interfaces for older adults.
 
![Figure](https://farm5.staticflickr.com/4163/34795384576_820fe3d44b_c.jpg)

**A Framework for Interactive Mindfulness Meditation Using Attention-Regulation Process**
*Niksirat, K.S., Silpasuwanchai, C., Ahmed, M., Cheng, P., Ren, X*
Abstract: We are often overwhelmed by everyday stressors. Mindfulness meditation can help slow things down and bring one’s attention into the present moment. Given the prevalence of smartphones, mindfulness-based mobile applications (MBMAs) have received much attention. Current MBMAs mainly use the guided meditation method which may not be always effective, e.g., users may not be able to follow the pace of instructions and they need a private environment. This paper presents a framework for interactive MBMAs which allows users to self-regulate their attention according to their abilities and conditions. The framework is described by an Attention-Regulation Process and has two components: (1) Relaxation Response and (2) Attention Restoration Theory. The framework is validated by our experiment. It also informs future development for interactive meditation and has broad implications for designing mindfulness and well-being.
 
**Understanding the Role of Human Senses in Interactive Meditation**
*Ahmed, M., Silpasuwanchai, C., Niksirat, K.S., Ren, X*
Abstract: In our fast-paced society, stress and anxiety have become increasingly common. Meditation for relaxation has received much attention. Meditation apps exploit various senses, e.g., touch, audio and vision, but the relationship between human senses and interactive meditation is not well understood. This paper empirically evaluates the effects of single and combined human senses on interactive meditation. We found that the effectiveness of human senses can be defined by their respective roles in maintaining the balance between relaxation and focus. This work is the first to attempt to understand these relationships. The findings have broad implications for the field of multi-modal interaction and interactive meditation applications.

**Enhancing Pen-based Interaction using Electrovibration and Vibration Haptic Feedback**
*Wang, Q., Ren, X., Sun, X.*
Abstract: This paper presents the EV^2-Pen which leverages electrovibration technology and vibration technology in pen interaction. Electrovibration technology can produce multisensory feedback when the pen is in motion (sliding/moving on the screen), and vibration technology can provide vibrative feedback when the pen is stationary (pointing/resting on the screen). We conducted an experiment to investigate user performance with the EV^2-Pen. The results indicated that the EV^2-Pen outperformed the EV-Pen in pointing-steering tasks. Finally, we discuss the characteristics of the EV^2-Pen, and explore some possible applications and scenarios.
 
**Towards Cognitive Enhancement of the Elderly: A UX Study of a Multitasking Motion Video Game**
*Niksirat, K.S., Silpasuwanchai, C., Ren, X., Wang, Z.*
Abstract: Cognitive impairments decrease the quality of life of the elderly. Earlier studies show multitasking sedentary video games are an effective intervention. However, little work has studied multitasking motion video games which can be more directly beneficial for overall wellbeing. This project investigates the efficacy of multitasking motion video games for the cognitive enhancement of the elderly. As a response to this situation, we developed a custom-made game called Safari Move. Here we report the initial step towards our goal in which we studied whether or not elderly people enjoy playing our game. Two important game elements were studied - skill balancing methods and controller types. Our results demonstrate that our participants enjoyed playing our game, and that they prefer manual over dynamic difficulty adjustment, and Microsoft Kinect over Gamepad. Future work will use neuroimaging and cognitive assessment tools to investigate the effectiveness of Safari Move to enhance cognitive function.